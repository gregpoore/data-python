def categorizequora(train_data,test_data,train_class):
    cf= ExtraTreesClassifier()
    cf.fit(train_data,train_class)
    #print (cf.feature_importances_)
    
    #lsvmcf = sklearn.svm.LinearSVC(penalty='l2', loss='l2', dual=True, tol=0.0001, C=100.0)
    lgr = linear_model.LogisticRegression(C=100.0,penalty='l1')    
    knn = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=10, p=2, metric='minkowski', metric_params=None)
    svmcf = sklearn.svm.SVC(C=1000.0, kernel='rbf', degree=1, gamma=0.01,  probability=True)
    cf = DecisionTreeClassifier() 
    dct = DecisionTreeClassifier(criterion='gini', splitter='best',  min_samples_split=7, min_samples_leaf=4)
    rf = RandomForestClassifier(n_estimators=10, criterion='gini',  min_samples_split=7, min_samples_leaf=4, max_features='auto')
    gnb = GaussianNB()
    adbst = sklearn.ensemble.AdaBoostClassifier(base_estimator=rf, n_estimators=5, learning_rate=1.0, algorithm='SAMME.R', random_state=True)
    cf = adbst
    #train_data = train_data[:,(0,1,3,4,10,11,19,20)]
    #test_data = test_data[:,(0,1,3,4,10,11,19,20)]
    cf.fit(train_data,train_class)
    return cf.predict(test_data)

def nrmlize(train_data,test_data):
    nrml =sklearn.preprocessing.MinMaxScaler()
    
    nrml.fit(train_data)
    train_data = nrml.transform(train_data)
    test_data = nrml.transform(test_data)
    return train_data,test_data
